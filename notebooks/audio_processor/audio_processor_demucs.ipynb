{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Audio Enhancement using Demucs\n",
                "\n",
                "This notebook demonstrates how to enhance audio using the `Demucs` library. We will:\n",
                "1. Load and preprocess an audio file.\n",
                "2. Apply the Demucs model to enhance the audio.\n",
                "3. Visualize and output the enhanced audio.\n",
                "\n",
                "## Explanation\n",
                "Demucs is a deep learning model designed for music source separation, but it can also be used for general audio enhancement. It is particularly effective at isolating vocals from background music. This can be useful for speech-to-text processing when the goal is to focus on the spoken words and minimize the impact of background sounds. However, it may not be as effective for non-musical background noise.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Install Requirements\n",
                "\n",
                "Install torch, numpy, matplotlib, soundfile and demucs from the actively\n",
                "maintained github repository."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup Environment\n",
                "import subprocess\n",
                "\n",
                "def run_command(name=None, command=None):\n",
                "    \"\"\"run_command _summary_\n",
                "\n",
                "    Args:\n",
                "        name (_type_, optional): _description_. Defaults to None.\n",
                "        command (_type_, optional): _description_. Defaults to None.\n",
                "    \"\"\"\n",
                "    display_name = name if name else f\"'{command}'\"\n",
                "    print(f\"Running {display_name}... \", end=\"\")\n",
                "    try:\n",
                "        if command:\n",
                "            subprocess.run(command, check=True, shell=True)\n",
                "        else:\n",
                "            subprocess.run(name, check=True, shell=True)\n",
                "        print(\"\\033[1;32mOK\\033[0m\")  # Bold Green\n",
                "    except subprocess.CalledProcessError as e:\n",
                "        if e.returncode == 1:  # Assuming '1' is a warning\n",
                "            print(\"\\033[1;33mWARNING\\033[0m\")  # Bold Yellow\n",
                "        else:\n",
                "            print(\"\\033[1;31mERROR\\033[0m\")  # Bold Red\n",
                "\n",
                "# Install torch, numpy, matplotlib, soundfile\n",
                "run_command(name=\"pip install torch numpy matplotlib soundfile\", command=\"PIP_ROOT_USER_ACTION=ignore pip install -U -q torch numpy matplotlib soundfile\")\n",
                "\n",
                "# Install demucs from GitHub\n",
                "run_command(name=\"pip install demucs\", command=\"PIP_ROOT_USER_ACTION=ignore pip install --disable-pip-version-check -U -q 'git+https://github.com/adefossez/demucs#egg=demucs'\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Load Libraries and Discover GPU Resources"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import necessary libraries\n",
                "import torch\n",
                "import numpy as np\n",
                "import soundfile as sf\n",
                "import matplotlib.pyplot as plt\n",
                "from demucs import pretrained\n",
                "from demucs.apply import apply_model\n",
                "\n",
                "# Check to see what GPU resources are available\n",
                "def get_best_device():\n",
                "    if torch.cuda.is_available():\n",
                "        torch.device(\"cuda\")\n",
                "        print(\"Using CUDA\")\n",
                "        return \"cuda\"\n",
                "    elif torch.backends.mps.is_available():\n",
                "        torch.device(\"mps\")\n",
                "        print(\"Using MPS\")\n",
                "        return \"mps\"\n",
                "    else:\n",
                "        torch.device(\"cpu\")\n",
                "        print(\"Using CPU\")\n",
                "        return \"cpu\"\n",
                "device = get_best_device()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Load the Audio File\n",
                "\n",
                "We start by loading an audio file using `soundfile`. The audio needs to be in a format supported by `Demucs`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the audio file\n",
                "audio_filepath = \"../../test_pcm.wav\"\n",
                "audio, sample_rate = sf.read(audio_filepath)\n",
                "\n",
                "# Plot the audio waveform\n",
                "plt.figure(figsize=(15, 5))\n",
                "plt.plot(np.linspace(0, len(audio) / sample_rate, num=len(audio)), audio)\n",
                "plt.title('Audio Waveform')\n",
                "plt.xlabel('Time [s]')\n",
                "plt.ylabel('Amplitude')\n",
                "plt.show()\n",
                "\n",
                "# Play the filtered audio from memory\n",
                "import IPython.display as ipd\n",
                "ipd.Audio(audio, rate=sample_rate)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Apply Demucs\n",
                "\n",
                "Next, we apply the Demucs model to the audio file to enhance it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply Demucs\n",
                "model = pretrained.get_model('htdemucs')\n",
                "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "model.eval()\n",
                "\n",
                "audio_stereo = np.tile(audio, (2, 1))\n",
                "audio_stereo = np.expand_dims(audio_stereo, axis=0)\n",
                "waveform_tensor = torch.tensor(audio_stereo, dtype=torch.float32)\n",
                "\n",
                "with torch.no_grad():\n",
                "    sources = apply_model(model, waveform_tensor, split=True, overlap=0.25)[0]\n",
                "\n",
                "vocals = sources[3].cpu().numpy()\n",
                "vocals = vocals / np.max(np.abs(vocals))\n",
                "vocals_mono = vocals.mean(axis=0)\n",
                "\n",
                "# Plot the enhanced audio waveform\n",
                "plt.figure(figsize=(15, 5))\n",
                "plt.plot(np.linspace(0, len(vocals_mono) / sample_rate, num=len(vocals_mono)), vocals_mono)\n",
                "plt.title('Enhanced Audio Waveform')\n",
                "plt.xlabel('Time [s]')\n",
                "plt.ylabel('Amplitude')\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Save & Listen to Enhanced Audio\n",
                "\n",
                "We save the enhanced audio to a new file and inspect the before and after results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import IPython.display as ipd\n",
                "from IPython.display import display, HTML\n",
                "\n",
                "# Save the enhanced audio\n",
                "output_filepath = \"../enhanced_audio.wav\"\n",
                "#sf.write(output_filepath, vocals_mono, sample_rate)\n",
                "print(f\"Enhanced audio saved to {output_filepath}\")\n",
                "\n",
                "# Function to convert a matplotlib plot to a base64 encoded PNG image\n",
                "def plt_to_base64(x, y, title):\n",
                "    \"\"\"Convert a matplotlib plot to a base64 encoded PNG image.\"\"\"\n",
                "    import io\n",
                "    import base64\n",
                "    plt.figure(figsize=(7, 5))\n",
                "    plt.plot(x, y)\n",
                "    plt.title(title)\n",
                "    plt.xlabel('Time (s)')\n",
                "    plt.ylabel('Amplitude')\n",
                "    buf = io.BytesIO()\n",
                "    plt.savefig(buf, format='png')\n",
                "    buf.seek(0)\n",
                "    image_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
                "    plt.close()\n",
                "    return image_base64\n",
                "\n",
                "# Generate the waveforms for the original and noise-reduced audio\n",
                "time_original = np.linspace(0, len(audio) / sample_rate, num=len(audio))\n",
                "time_reduced = np.linspace(0, len(vocals_mono) / sample_rate, num=len(vocals_mono))\n",
                "\n",
                "# Create the HTML layout for plots and audio widgets side by side\n",
                "html_content = f\"\"\"\n",
                "<div style=\"display: flex; justify-content: space-around; align-items: flex-start;\">\n",
                "    <div>\n",
                "        <h4>Original Audio</h4>\n",
                "        <img src=\"data:image/png;base64,{plt_to_base64(time_original, audio, 'Original Audio')}\" alt=\"Original Audio Waveform\"/>\n",
                "        <br>\n",
                "        {ipd.Audio(audio, rate=sample_rate)._repr_html_()}\n",
                "    </div>\n",
                "    <div>\n",
                "        <h4>Noise-Reduced Audio</h4>\n",
                "        <img src=\"data:image/png;base64,{plt_to_base64(time_reduced, vocals_mono, 'Demucs Filtered Vocals')}\" alt=\"Demucs Filtered Vocal Waveform\"/>\n",
                "        <br>\n",
                "        {ipd.Audio(vocals_mono, rate=sample_rate)._repr_html_()}\n",
                "    </div>\n",
                "</div>\n",
                "\"\"\"\n",
                "\n",
                "# Display the HTML content\n",
                "display(HTML(html_content))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Free up Resources\n",
                "*Remove any local files and free up GPU resources.*\n",
                "\n",
                "Press the large red button below to get started! 🚀"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remove the output file\n",
                "!rm -rf {output_filepath}\n",
                "print(\"Local files deleted\")\n",
                "\n",
                "# Free up GPU memory\n",
                "torch.cuda.empty_cache()\n",
                "print(\"GPU memory freed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "\n",
                "In this notebook, we demonstrated how to enhance audio using the `Demucs` library. We loaded and preprocessed the audio, applied the Demucs model and visualized the enhanced audio."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
