{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Audio Enhancement using Demucs\n",
                "\n",
                "This notebook demonstrates how to enhance audio using the `Demucs` library. We will:\n",
                "1. Load and preprocess an audio file.\n",
                "2. Apply the Demucs model to enhance the audio.\n",
                "3. Visualize and output the enhanced audio.\n",
                "\n",
                "## Explanation\n",
                "Demucs is a deep learning model designed for music source separation, but it can also be used for general audio enhancement. It is particularly effective at isolating vocals from background music. This can be useful for speech-to-text processing when the goal is to focus on the spoken words and minimize the impact of background sounds. However, it may not be as effective for non-musical background noise.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Install Requirements\n",
                "\n",
                "Install torch, numpy, matplotlib, soundfile and demucs from the actively\n",
                "maintained github repository."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup installers\n",
                "commands = [\n",
                "    (\"PIP_ROOT_USER_ACTION=ignore pip install -q torch\", \"Install torch\"),\n",
                "    (\"PIP_ROOT_USER_ACTION=ignore pip install -q numpy\", \"Install numpy\"),\n",
                "    (\"PIP_ROOT_USER_ACTION=ignore pip install -q matplotlib\", \"Install matplotlib\"),\n",
                "    (\"PIP_ROOT_USER_ACTION=ignore pip install -q soundfile\", \"Install soundfile\"),\n",
                "    (\"PIP_ROOT_USER_ACTION=ignore pip install -q -U git+https://github.com/adefossez/demucs#egg=demucs\", \"Install demucs from current maintainer repo\")\n",
                "]\n",
                "\n",
                "# Import the utils module which sets up the environment\n",
                "from modules import utils\n",
                "from modules import disable_warnings\n",
                "\n",
                "# Use LogTools\n",
                "log_tools = utils.LogTools()\n",
                "\n",
                "# Execute\n",
                "log_tools.command_state(commands)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Load Libraries and Discover GPU Resources"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import necessary libraries\n",
                "import torch\n",
                "import numpy as np\n",
                "import soundfile as sf\n",
                "import matplotlib.pyplot as plt\n",
                "from demucs import pretrained\n",
                "from demucs.apply import apply_model\n",
                "import torch\n",
                "\n",
                "# Check to see what GPU resources are available\n",
                "def get_best_device():\n",
                "    if torch.cuda.is_available():\n",
                "        print(\"Using CUDA\")\n",
                "        return torch.device(\"cuda\")\n",
                "    elif torch.backends.mps.is_available():\n",
                "        print(\"Using MPS\")\n",
                "        return torch.device(\"mps\")\n",
                "    else:\n",
                "        print(\"Using CPU\")\n",
                "        return torch.device(\"cpu\")\n",
                "\n",
                "device = get_best_device()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Load the Audio File\n",
                "\n",
                "We start by loading an audio file using `soundfile`. The audio needs to be in a format supported by `Demucs`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the audio file\n",
                "audio_filepath = \"../../test_pcm.wav\"\n",
                "audio, sample_rate = sf.read(audio_filepath)\n",
                "\n",
                "# Plot the audio waveform\n",
                "plt.figure(figsize=(15, 5))\n",
                "plt.plot(np.linspace(0, len(audio) / sample_rate, num=len(audio)), audio)\n",
                "plt.title('Audio Waveform')\n",
                "plt.xlabel('Time [s]')\n",
                "plt.ylabel('Amplitude')\n",
                "plt.show()\n",
                "\n",
                "# Play the filtered audio from memory\n",
                "import IPython.display as ipd\n",
                "ipd.Audio(audio, rate=sample_rate)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Apply Demucs\n",
                "\n",
                "Next, we apply the Demucs model to the audio file to enhance it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply Demucs\n",
                "model = pretrained.get_model('htdemucs')\n",
                "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "model.eval()\n",
                "\n",
                "audio_stereo = np.tile(audio, (2, 1))\n",
                "audio_stereo = np.expand_dims(audio_stereo, axis=0)\n",
                "waveform_tensor = torch.tensor(audio_stereo, dtype=torch.float32)\n",
                "\n",
                "with torch.no_grad():\n",
                "    sources = apply_model(model, waveform_tensor, split=True, overlap=0.25)[0]\n",
                "\n",
                "vocals = sources[3].cpu().numpy()\n",
                "vocals = vocals / np.max(np.abs(vocals))\n",
                "vocals_mono = vocals.mean(axis=0)\n",
                "\n",
                "# Plot the enhanced audio waveform\n",
                "plt.figure(figsize=(15, 5))\n",
                "plt.plot(np.linspace(0, len(vocals_mono) / sample_rate, num=len(vocals_mono)), vocals_mono)\n",
                "plt.title('Enhanced Audio Waveform')\n",
                "plt.xlabel('Time [s]')\n",
                "plt.ylabel('Amplitude')\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Save & Listen to Enhanced Audio\n",
                "\n",
                "We save the enhanced audio to a new file and inspect the before and after results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import IPython.display as ipd\n",
                "from IPython.display import display, HTML\n",
                "\n",
                "# Save the enhanced audio\n",
                "output_filepath = \"../enhanced_audio.wav\"\n",
                "# sf.write(output_filepath, vocals_mono, sample_rate) # Disabled as we don't\n",
                "# need the file\n",
                "print(f\"Enhanced audio saved to {output_filepath}\")\n",
                "\n",
                "# Function to convert a matplotlib plot to a base64 encoded PNG image\n",
                "def plt_to_base64(x, y, title):\n",
                "    \"\"\"Convert a matplotlib plot to a base64 encoded PNG image.\"\"\"\n",
                "    import io\n",
                "    import base64\n",
                "    plt.figure(figsize=(7, 5))\n",
                "    plt.plot(x, y)\n",
                "    plt.title(title)\n",
                "    plt.xlabel('Time (s)')\n",
                "    plt.ylabel('Amplitude')\n",
                "    buf = io.BytesIO()\n",
                "    plt.savefig(buf, format='png')\n",
                "    buf.seek(0)\n",
                "    image_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
                "    plt.close()\n",
                "    return image_base64\n",
                "\n",
                "# Generate the waveforms for the original and noise-reduced audio\n",
                "time_original = np.linspace(0, len(audio) / sample_rate, num=len(audio))\n",
                "time_reduced = np.linspace(0, len(vocals_mono) / sample_rate, num=len(vocals_mono))\n",
                "\n",
                "# Create the HTML layout for plots and audio widgets side by side\n",
                "html_content = f\"\"\"\n",
                "<div style=\"display: flex; justify-content: space-around; align-items: flex-start;\">\n",
                "    <div>\n",
                "        <h4>Original Audio</h4>\n",
                "        <img src=\"data:image/png;base64,{plt_to_base64(time_original, audio, 'Original Audio')}\" alt=\"Original Audio Waveform\"/>\n",
                "        <br>\n",
                "        {ipd.Audio(audio, rate=sample_rate)._repr_html_()}\n",
                "    </div>\n",
                "    <div>\n",
                "        <h4>Noise-Reduced Audio</h4>\n",
                "        <img src=\"data:image/png;base64,{plt_to_base64(time_reduced, vocals_mono, 'Demucs Filtered Vocals')}\" alt=\"Demucs Filtered Vocal Waveform\"/>\n",
                "        <br>\n",
                "        {ipd.Audio(vocals_mono, rate=sample_rate)._repr_html_()}\n",
                "    </div>\n",
                "</div>\n",
                "\"\"\"\n",
                "\n",
                "# Display the HTML content\n",
                "display(HTML(html_content))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Free up Resources\n",
                "*Remove any local files and free up GPU resources.*\n",
                "\n",
                "Press the large red button below to get started! ðŸš€"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remove the output file\n",
                "!rm -rf {output_filepath}\n",
                "print(\"Local files deleted\")\n",
                "\n",
                "# Free up GPU memory\n",
                "torch.cuda.empty_cache()\n",
                "print(\"GPU memory freed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "\n",
                "In this notebook, we demonstrated how to enhance audio using the `Demucs` library. We loaded and preprocessed the audio, applied the Demucs model and visualized the enhanced audio."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
