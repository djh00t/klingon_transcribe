{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Audio Dynamic Range Compression\n",
                "\n",
                "This notebook demonstrates how to apply dynamic range compression to audio using the `librosa` library. We will:\n",
                "1. Load and preprocess an audio file.\n",
                "2. Apply dynamic range compression to the audio.\n",
                "3. Visualize and output the compressed audio.\n",
                "\n",
                "## Explanation\n",
                "Dynamic range compression reduces the volume of loud sounds and amplifies quieter sounds, resulting in a more consistent audio level. This can be useful for speech-to-text processing as it ensures that all parts of the speech are audible, even if the speaker's volume varies. However, over-compression can lead to a loss of natural dynamics in the audio.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Install Requirements"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup Environment\n",
                "import subprocess\n",
                "\n",
                "# Suppress the warning by setting the PIP_ROOT_USER_ACTION environment variable\n",
                "!export PIP_ROOT_USER_ACTION=ignore\n",
                "\n",
                "def run_command(name=None, command=None):\n",
                "    \"\"\"run_command _summary_\n",
                "\n",
                "    Args:\n",
                "        name (_type_, optional): _description_. Defaults to None.\n",
                "        command (_type_, optional): _description_. Defaults to None.\n",
                "    \"\"\"\n",
                "    display_name = name if name else f\"'{command}'\"\n",
                "    print(f\"Running {display_name}... \", end=\"\")\n",
                "    try:\n",
                "        if command:\n",
                "            subprocess.run(command, check=True, shell=True)\n",
                "        else:\n",
                "            subprocess.run(name, check=True, shell=True)\n",
                "        print(\"\\033[1;32mOK\\033[0m\")  # Bold Green\n",
                "    except subprocess.CalledProcessError as e:\n",
                "        if e.returncode == 1:  # Assuming '1' is a warning\n",
                "            print(\"\\033[1;33mWARNING\\033[0m\")  # Bold Yellow\n",
                "        else:\n",
                "            print(\"\\033[1;31mERROR\\033[0m\")  # Bold Red\n",
                "\n",
                "# Install torch, numpy, matplotlib, soundfile\n",
                "run_command(name=\"pip install librosa numpy matplotlib soundfile\", command=\"PIP_ROOT_USER_ACTION=ignore pip install -q librosa numpy matplotlib soundfile\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Load Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import necessary libraries\n",
                "import librosa\n",
                "import soundfile as sf\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Load the Audio File\n",
                "\n",
                "We start by loading an audio file using `soundfile`. The audio needs to be in a format supported by `librosa`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the audio file\n",
                "audio_filepath = \"../../test_pcm.wav\"\n",
                "audio, sample_rate = sf.read(audio_filepath)\n",
                "\n",
                "# Plot the audio waveform\n",
                "plt.figure(figsize=(15, 5))\n",
                "plt.plot(np.linspace(0, len(audio) / sample_rate, num=len(audio)), audio)\n",
                "plt.title('Audio Waveform')\n",
                "plt.xlabel('Time [s]')\n",
                "plt.ylabel('Amplitude')\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Apply Dynamic Range Compression\n",
                "\n",
                "Next, we apply dynamic range compression to the audio file using `librosa.effects.percussive`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply dynamic range compression\n",
                "compressed_audio = librosa.effects.percussive(audio)\n",
                "\n",
                "# Plot the compressed audio waveform\n",
                "plt.figure(figsize=(15, 5))\n",
                "plt.plot(np.linspace(0, len(compressed_audio) / sample_rate, num=len(compressed_audio)), compressed_audio)\n",
                "plt.title('Compressed Audio Waveform')\n",
                "plt.xlabel('Time [s]')\n",
                "plt.ylabel('Amplitude')\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Save & Compare Compressed Audio\n",
                "\n",
                "We save the compressed audio to a new file and inspect the before and after results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import IPython.display as ipd\n",
                "from IPython.display import display, HTML\n",
                "\n",
                "# Save the compressed audio\n",
                "output_filepath = \"../compressed_audio.wav\"\n",
                "# sf.write(output_filepath, compressed_audio, sample_rate)\n",
                "print(f\"Compressed audio saved to {output_filepath}\")\n",
                "\n",
                "# Function to convert a matplotlib plot to a base64 encoded PNG image\n",
                "def plt_to_base64(x, y, title):\n",
                "    \"\"\"Convert a matplotlib plot to a base64 encoded PNG image.\"\"\"\n",
                "    import io\n",
                "    import base64\n",
                "    plt.figure(figsize=(7, 5))\n",
                "    plt.plot(x, y)\n",
                "    plt.title(title)\n",
                "    plt.xlabel('Time (s)')\n",
                "    plt.ylabel('Amplitude')\n",
                "    buf = io.BytesIO()\n",
                "    plt.savefig(buf, format='png')\n",
                "    buf.seek(0)\n",
                "    image_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
                "    plt.close()\n",
                "    return image_base64\n",
                "\n",
                "# Generate the waveforms for the original and compressed audio\n",
                "time_original = np.linspace(0, len(audio) / sample_rate, num=len(audio))\n",
                "time_compressed = np.linspace(0, len(compressed_audio) / sample_rate, num=len(compressed_audio))\n",
                "\n",
                "# Create the HTML layout for plots and audio widgets side by side\n",
                "html_content = f\"\"\"\n",
                "<div style=\"display: flex; justify-content: space-around; align-items: flex-start;\">\n",
                "    <div>\n",
                "        <h4>Original Audio</h4>\n",
                "        <img src=\"data:image/png;base64,{plt_to_base64(time_original, audio, 'Original Audio')}\" alt=\"Original Audio Waveform\"/>\n",
                "        <br>\n",
                "        {ipd.Audio(audio, rate=sample_rate)._repr_html_()}\n",
                "    </div>\n",
                "    <div>\n",
                "        <h4>Compressed Audio</h4>\n",
                "        <img src=\"data:image/png;base64,{plt_to_base64(time_compressed, compressed_audio, 'Compressed Audio')}\" alt=\"Compressed Audio Waveform\"/>\n",
                "        <br>\n",
                "        {ipd.Audio(compressed_audio, rate=sample_rate)._repr_html_()}\n",
                "    </div>\n",
                "</div>\n",
                "\"\"\"\n",
                "\n",
                "# Display the HTML content\n",
                "display(HTML(html_content))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "\n",
                "In this notebook, we demonstrated how to apply dynamic range compression to audio using the `librosa` library. We loaded and preprocessed the audio, applied compression and visualized the compressed audio."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
